{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion-ANN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT56QWEJMOe2",
        "outputId": "9e479d7f-3946-417e-cd3c-95c9f134cb5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.43.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        " "
      ],
      "metadata": {
        "id": "Y36GK27vOUng"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "metadata": {
        "id": "9nUVIqLkOt6R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "(X_train,y_train),(X_test,y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1GptRbhO-3k",
        "outputId": "0afbf118-020a-4780-a4d3-49cb38319119"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP_SRhxEPtUs",
        "outputId": "fc4910bd-7a7b-4ba9-e935-6a375f3851a8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data -- to save the training time\n",
        "X_train = X_train/255.0\n",
        "y_train = y_train/255.0"
      ],
      "metadata": {
        "id": "6r7706KXP-7o"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping the dataset\n",
        "X_train=X_train.reshape(-1,28*28)"
      ],
      "metadata": {
        "id": "eXAnSHq6QBBM"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RixKVOt5QaLh",
        "outputId": "475c6c90-8cd0-442b-c68b-beb7193f3357"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd_df = pd.DataFrame(X_train)"
      ],
      "metadata": {
        "id": "j5Ab_0bRQmzu"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_df['label']= y_train"
      ],
      "metadata": {
        "id": "jW26KGWuQ3NG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "huleEavyTH8H",
        "outputId": "48e34ed5-5c8d-44d5-a1d8-01af0481fcbf"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ff90584d-eabe-4edd-8e5e-5404bf12368c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000631</td>\n",
              "      <td>0.002891</td>\n",
              "      <td>0.001584</td>\n",
              "      <td>0.000830</td>\n",
              "      <td>0.000738</td>\n",
              "      <td>0.000661</td>\n",
              "      <td>0.001338</td>\n",
              "      <td>0.002584</td>\n",
              "      <td>0.002045</td>\n",
              "      <td>0.000246</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000754</td>\n",
              "      <td>0.002092</td>\n",
              "      <td>0.003368</td>\n",
              "      <td>0.003322</td>\n",
              "      <td>0.003506</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003691</td>\n",
              "      <td>0.003737</td>\n",
              "      <td>0.003291</td>\n",
              "      <td>0.003445</td>\n",
              "      <td>0.002491</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002138</td>\n",
              "      <td>0.002245</td>\n",
              "      <td>0.001999</td>\n",
              "      <td>0.002076</td>\n",
              "      <td>0.002076</td>\n",
              "      <td>0.002107</td>\n",
              "      <td>0.001922</td>\n",
              "      <td>0.001907</td>\n",
              "      <td>0.001922</td>\n",
              "      <td>0.001861</td>\n",
              "      <td>0.001830</td>\n",
              "      <td>0.001753</td>\n",
              "      <td>0.001999</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000338</td>\n",
              "      <td>0.001815</td>\n",
              "      <td>0.000369</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000738</td>\n",
              "      <td>0.001353</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000185</td>\n",
              "      <td>0.001538</td>\n",
              "      <td>0.003260</td>\n",
              "      <td>0.003153</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001569</td>\n",
              "      <td>0.001153</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.000877</td>\n",
              "      <td>0.000861</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000507</td>\n",
              "      <td>0.001476</td>\n",
              "      <td>0.002691</td>\n",
              "      <td>0.002399</td>\n",
              "      <td>0.000984</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.000830</td>\n",
              "      <td>0.002107</td>\n",
              "      <td>0.003137</td>\n",
              "      <td>0.002983</td>\n",
              "      <td>0.001569</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001123</td>\n",
              "      <td>0.002860</td>\n",
              "      <td>0.002722</td>\n",
              "      <td>0.002814</td>\n",
              "      <td>0.002691</td>\n",
              "      <td>0.002891</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002338</td>\n",
              "      <td>0.001307</td>\n",
              "      <td>0.002461</td>\n",
              "      <td>0.002045</td>\n",
              "      <td>0.001538</td>\n",
              "      <td>0.000185</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000538</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>0.000507</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002907</td>\n",
              "      <td>0.003168</td>\n",
              "      <td>0.002876</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003722</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.001077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000938</td>\n",
              "      <td>0.001569</td>\n",
              "      <td>0.002584</td>\n",
              "      <td>0.000384</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002138</td>\n",
              "      <td>0.002476</td>\n",
              "      <td>0.001138</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.002015</td>\n",
              "      <td>0.001338</td>\n",
              "      <td>0.001461</td>\n",
              "      <td>0.001492</td>\n",
              "      <td>0.001630</td>\n",
              "      <td>0.001461</td>\n",
              "      <td>0.001769</td>\n",
              "      <td>0.001676</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001030</td>\n",
              "      <td>0.003875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002215</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002061</td>\n",
              "      <td>0.001907</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002461</td>\n",
              "      <td>0.001230</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000907</td>\n",
              "      <td>0.003460</td>\n",
              "      <td>0.003353</td>\n",
              "      <td>0.000323</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003199</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002353</td>\n",
              "      <td>0.002983</td>\n",
              "      <td>0.003168</td>\n",
              "      <td>0.003414</td>\n",
              "      <td>0.003429</td>\n",
              "      <td>0.003214</td>\n",
              "      <td>0.003091</td>\n",
              "      <td>0.000861</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.002937</td>\n",
              "      <td>0.002445</td>\n",
              "      <td>0.001215</td>\n",
              "      <td>0.001307</td>\n",
              "      <td>0.002430</td>\n",
              "      <td>0.002937</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.001476</td>\n",
              "      <td>0.001646</td>\n",
              "      <td>0.001184</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001092</td>\n",
              "      <td>0.001015</td>\n",
              "      <td>0.000784</td>\n",
              "      <td>0.001030</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.000830</td>\n",
              "      <td>0.000846</td>\n",
              "      <td>0.000938</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.001061</td>\n",
              "      <td>0.001030</td>\n",
              "      <td>0.001030</td>\n",
              "      <td>0.001015</td>\n",
              "      <td>0.000969</td>\n",
              "      <td>0.001015</td>\n",
              "      <td>0.001061</td>\n",
              "      <td>0.001015</td>\n",
              "      <td>0.000830</td>\n",
              "      <td>0.000769</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000077</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 785 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff90584d-eabe-4edd-8e5e-5404bf12368c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff90584d-eabe-4edd-8e5e-5404bf12368c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff90584d-eabe-4edd-8e5e-5404bf12368c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         0    1    2    3    4  ...  780  781  782  783     label\n",
              "0      0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.000138\n",
              "1      0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.000000\n",
              "2      0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.000000\n",
              "3      0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.000046\n",
              "4      0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.000000\n",
              "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...\n",
              "59995  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.000077\n",
              "59996  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.000015\n",
              "59997  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.000046\n",
              "59998  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.000000\n",
              "59999  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.000077\n",
              "\n",
              "[60000 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape the test dataset in the same way\n",
        "\n",
        "X_test = X_test.reshape(-1,28*28)"
      ],
      "metadata": {
        "id": "HaHMT62QTJBZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building the artificial neural network\n"
      ],
      "metadata": {
        "id": "PJF59BKXUMun"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a squential model\n",
        "\n",
        "model = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "rFbiHBcYbcee"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding a first fully connected hidden layer\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=128,activation='relu',input_shape=(784,)))"
      ],
      "metadata": {
        "id": "QqqeukasbkSq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding a second layer with dropout\n",
        "# 20% dropout\n",
        "model.add(tf.keras.layers.Dropout(0.2))"
      ],
      "metadata": {
        "id": "IM92_1Jmb6mc"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the output layer\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=10,activation='softmax'))"
      ],
      "metadata": {
        "id": "Um1lP3iqcMRf"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the artificial neural network\n",
        "\n",
        "# compiling the model\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "QPesWwEpcW5T"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_j1DHSCfLj1",
        "outputId": "5b23ee98-5b1b-4f2f-ac73-dec78d212f0e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_train', X_train.shape,'y_train',y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA713a8Jg-sN",
        "outputId": "7ef44f90-ffa9-4cdf-8a51-5ebb5cbd142f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train (60000, 784) y_train (60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeUwO47nfNi6",
        "outputId": "c7aaa543-fc22-4113-dd84-6875f9650c57"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.3787e-08 - sparse_categorical_accuracy: 0.1000\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 4.2717e-09 - sparse_categorical_accuracy: 0.1000\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5259e-09 - sparse_categorical_accuracy: 0.1000\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 7.0333e-10 - sparse_categorical_accuracy: 0.1000\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 3.2783e-10 - sparse_categorical_accuracy: 0.1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29fb9e8b50>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "test_loss,test_accuracy = model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zms-70qrf1EP",
        "outputId": "53190cbd-e4e0-4f7d-8aff-6c3e75c2bb5a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 388589.2188 - sparse_categorical_accuracy: 0.1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('test accuracy- ', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7kF2giVggYE",
        "outputId": "f548812d-342f-456e-bead-6eef5b57b29b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy-  0.10000000149011612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# second model using cnn"
      ],
      "metadata": {
        "id": "F5QM5SYXgvy6"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10"
      ],
      "metadata": {
        "id": "qZ-WMVfHods6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_name=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
      ],
      "metadata": {
        "id": "pfAeepz8omTC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "(X_train,y_train),(X_test,y_test)=cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8ZjKELpo1zA",
        "outputId": "828d5f4b-5410-41f0-e0be-4cb6d6fe6cdc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "170508288/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the dataset\n",
        "X_train=X_train/255.0"
      ],
      "metadata": {
        "id": "CyUpgLMopAb5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwAEj46XpmIY",
        "outputId": "8435c578-7460-4314-c7b1-527f69c1bdd6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "APO0CDX7pt02"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test= X_test/255.0"
      ],
      "metadata": {
        "id": "FtgJlEb2p3oG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_test[6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "rGZfxvavqFZG",
        "outputId": "241c0552-46bb-409a-85ed-d6c95b851f5b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6202bb7650>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAeeUlEQVR4nO2daYyc13Wm31N7r2Q31zYpcdFi7dZCy8rEi2zFHsVxIDsz0FgYGBrAMDMDGxgPnB+CBxhrgPnhDMY2/MsBHSlWEtuyvGikJEJsR3CiyIklUbJMiqREUSTFxc1uLk32WvuZH1XEUMJ9bzfZ7Cra930Agt339P2+U7e+U1/VfeucY+4OIcRvP5luOyCE6AwKdiESQcEuRCIo2IVIBAW7EImgYBciEXKLmWxmdwP4OoAsgD939y/H/n4ga74yH359IcNRm0XOlc1wSTGb4TPN+DxH2GYRR2LKZqPJbc0LVkTDzsQO14icLOZH1MVMMTynr5f7MTVFbfXIGtecG3ONenC80uBzPJPlJ8vyC7XW5E9oLmIzYmtGHjO7TKebjnIzvCB2oTq7mWUB7AXwYQBHALwA4D53383mbCpl/cHL+4K2kX6+GGtL4cUvWfiJBICBEn9cy/v5KmYzNWprWCM4nsnz49W4i5ia4495rsKP2XB+wWUzYVstEpoTM/wxz1QjQRE5ZmPwiuB4/bbb6JzJf/pHahvPcT/GqgVqG545Hhw/MJGnc+r9g9SG/n7ux+wstS2rcFtxZiY4Ppvl10eWvAr/3ek6TtTDLxOLeRt/O4B97r7f3asAHgVwzyKOJ4RYQhYT7OsAHD7n9yPtMSHEJciiPrMvBDPbCmArAKyIvBUTQiwti7mzHwVw2Tm/r2+PvQV33+buW9x9y0BWwS5Et1hMsL8A4Coz22RmBQCfBPDkxXFLCHGxueC38e5eN7PPAfgxWtLbw+6+KzZnoAB88PKwbTCyo53Nh7e0p+eqdE7GuXziER2nGpFIytWwLZPhy1ip8+NNVqgJMzW+012P+MhciShNmJrjxshGPeoRzXF25mRwfP9TT9M5y3ya2jyyHhbzkbyb7O9fSefs6x+gtp2nx6htWSOiAEXWv0Au1bpFduOJIhN777yoz+zu/hSApxZzDCFEZ9A36IRIBAW7EImgYBciERTsQiSCgl2IRFjyb9CdS8Ec6/JhuaxRDyeZAECZJFzMVvkckuwEAKhyxQ6NWiw5JTweyyWqNvjr6XQk622GPzREXEQ2Fz5fI5LNN13jPpYjMmUlcsw6yQDKNLneOFnkD7q/yaXUQsSP4xaed3QwnJUHALsnw4kpAHBggie0bI74kSty/0tOst4uIOUwJr3pzi5EIijYhUgEBbsQiaBgFyIRFOxCJEJHd+PrDcfJ0+Gt8HKTv+40iuESQnNe4ifL8d3WyclJfq7YzjTZSI7VQKtH9kfnIuWlZiM7sfXI+fK1sK1GSmoBQCWy012OZNDEEjWcFNjridxepiIKxJk69zFjvCzVXCF8HRyp8l31xukyta1u8pAZyvEHMBDZJs+TZSxGlJyGnX8ijO7sQiSCgl2IRFCwC5EICnYhEkHBLkQiKNiFSISOSm9VZPBrC7f/mc5yqaw/H55TrXCpY2aW22an+WtcrD5dmcha5VhCSKROWzUioVUiyS4eEVgKxFaPtLyqxmwRHyMPGzUiy+UiWUO5eqSW30rekqC4gtvOjI4Gx32C15JbSy3AVIY/MRt6+TWcz0QKDvb0BIczkUypRjOS6UXQnV2IRFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJsCjpzcwOApgC0ABQd/ctsb+vIYPRTLiZ/YzzzCU/Gc5CKk/yzKW5iCzH86d4Wx0AKJP2PpVI9lckcQlufPmbET8smmUX9jHW/gkReTBmy8X8J4ucjRQH7MuGrw0AKN14M7W9YTz78Xgl3BtqyHnPqKnJE9S2oj+cgQkAlw/2UVt/5Pl00rOrXOG18IzU+ItxMXT2D7o7Xx0hxCWB3sYLkQiLDXYH8BMze9HMtl4Mh4QQS8Ni38a/192PmtlqAD81s1fd/Zlz/6D9IrAVAFYX9UZCiG6xqOhz96Pt/8cBPA7g9sDfbHP3Le6+ZZA0MBBCLD0XHH1m1mdmA2d/BvARAK9cLMeEEBeXxbyNXwPgcWtJMzkA33H3v49NKNea2DM6HbTVqrEUqrCt2eDyWiaSydUkxfoAoBDLRCNtejKRLLQMkesAIJPl87IRWSsTyRzLklS0yEOmLaMAAJE1hkekN3LIfER68+EhajsQyUZ8bv8Baps8dTI4/s4VK+icAef9wTZFdNs+448tW46sYzWcEefOpWV6fUdU1AsOdnffD+BdFzpfCNFZ9CFaiERQsAuRCAp2IRJBwS5EIijYhUiEjhacrDWaGJuYC9qKkVy0LFGaLCKvFTP8eA2SGQYAzcjrn1+IrBUrsBiZGFHlkI1kopUy4aysOiJ92XJ8rSr5SPZgnmeAZQphmzV4htqJQZ71tmf0GLXtf/1VastVwvJVqbGSzrkqy9eqb47LYdVIP716hctyeSLPZiPPWTOauxlGd3YhEkHBLkQiKNiFSAQFuxCJoGAXIhE6uhsPGBrklGZ8dzHHdsEju+psBx9AZBaQj+yQO5mZiczJR86Wy0R24yNKQ72XP231FeFkkp4a39ktlnj9v2nwXeScc1uNFN+bi2wiT9X5eowfDye0AIBF6skN5MPrP1Lmu+qrPVzzEAAaznfcmxEJpRLplcVyrzJN/jxH8qsourMLkQgKdiESQcEuRCIo2IVIBAW7EImgYBciETouvWVJokYmIiXkqHwVqUEXKcZlzUhduMjLH5XKInXrMpGklXyOS159Q4PUVh7gCSiNwd7guJ8MJyABQKMSaV8VqRk30+CSVzMXTmqplHiLpNM1rsv19yynto0beqitpz4ZHM9FauudqUbqF85yyS7XjLXl4uvYILKzxVpG0ZiIXIvUIoT4rULBLkQiKNiFSAQFuxCJoGAXIhEU7EIkwrzSm5k9DOBjAMbd/Yb22DCA7wHYCOAggHvdfWK+Y2UMKBJlIBdtaRQeb0Ykr0gJt6jRI34wk0d0w0akVlg9V6S26YgsNz7Fs7JKubC0NZsPS3IAUBoaoLbBy0eobcOmDdQ2ctl1wfHsMG+7NPvsz6mtcoI/5rHDh6nt6O6XguPH1nApbzLPZc/c2AlqWz4Vbm0GxLPlnMizmYiU1yBZdJHLd0F39m8BuPttYw8AeNrdrwLwdPt3IcQlzLzB3u63fuptw/cAeKT98yMAPn6R/RJCXGQu9DP7Gncfbf98DK2OrkKIS5hFb9B560Mu/aRgZlvNbLuZbZ+NfE1VCLG0XGiwj5nZCAC0/x9nf+ju29x9i7tv6Y2UWhJCLC0XGuxPAri//fP9AJ64OO4IIZaKhUhv3wVwJ4CVZnYEwJcAfBnAY2b2aQBvArh3ISczOEqkRU4uoodlLexm7EOBZy/sdazJE8DQZHJHzI8c92OyFmkXVONH7bvqRmq75kMfCY6vWLeezsn080y04jIuQ/E8LqDeCEt9J2tcQtt8+x3U9r7Lr6S2Xb94jtr+7IVfBMf/5eCbdM7AwDJq+8Cma6nNDx2gtsbJo9xGrqtMREdrUFukwCm1nJ3qfh8x3TXfXCHEpYO+QSdEIijYhUgEBbsQiaBgFyIRFOxCJEJHC05mABSJZOCRL9wYscUK8mUir2OxB12PNIlz0tOt6Vyvm81GikpuvpraVt50E7UVN26mtvFcWDbaufcInzNGvxOFuYkz1DY1fZraTk2ECzOejhRs3HLHFmr7N1+4k9r638ef6xfvCMt5P/qnv6dzTkyOUtvqgWFquz0iD85O8oy4TC1sy0XEzTqLIzpDd3YhkkHBLkQiKNiFSAQFuxCJoGAXIhEU7EIkQkelN4MhRwowVmMvO6RmozUimXKRYpTZyGvcaeNyR55k5tWsROcsu+YGaqttuILanj/OJa/TB8OZXADQLIT7nu3av5/OObR/H7X1RgolrooUqhw9+fZKZi0qxqXI933gA9Q2M1Oltp6+ldT2/j/8d8Hxf929m845ePgNatt1hBe3LPTwDEEr8ky6gUo4E3Aoci1KehNCUBTsQiSCgl2IRFCwC5EICnYhEqGju/GAwXLhU1okmSSbCW/He4PvVrJ6cS0bf42bq0bmZcK+5zfzxJRTkXpmu3a+Qm2nJ6aobXjlamqrD4XP12jy3exsga/H7BT3Az1D1JRfFq5rd831N9M577mL78aXI/X6ctP8Obvp1t8Jjt951+/TOY9996+ozav8mtux71VqG8jlqW1VNmxrNPm5elALjkdKKOrOLkQqKNiFSAQFuxCJoGAXIhEU7EIkgoJdiERYSPunhwF8DMC4u9/QHnsQwGcAHG//2Rfd/an5juUGNFmtuUgvoQxJaon1iawaFyGq/TxhYXjNO6mtXA4f8/SqtXTOiwcOUVuByJAAMDzMfVy5gtuONMKSTLUeHgeA/kF+vEwfT/JZeflGavvgbe8Ojt9198fonFXrNlBbtcKfz1yJJ9eUK+GadwUiDQLAjdfz+n/H9vEEmpNzvM7czBCvXXfDDbcFx1fN8Xp9EzufD44vNhHmWwDuDox/zd1vbv+bN9CFEN1l3mB392cAhPMVhRC/MSzmM/vnzGyHmT1sZvyrVEKIS4ILDfZvALgCwM0ARgF8hf2hmW01s+1mtn0m1g9ZCLGkXFCwu/uYuzfcvQngmwBuj/ztNnff4u5b+jLa/BeiW1xQ9JnZyDm/fgIAz+gQQlwSLER6+y6AOwGsNLMjAL4E4E4zuxmtnf6DAP54oSd0VhuuyXU0Um4LtDgdgFqpSG2nlvMthuErIy186mFH9p3kmWFrrr2R2g6/uZfaGrnIehjPYJuthiW262/gtfDuvjsktrS4avNGalu3bj21Da8Oy5HNyP3lxCledw95/lzXq3PU9u1v/UVw/NnHf0Tn3Lh6I7WV69z/iRr/mHrttXz93/t74Qy83NgYnfPzXTuC4wZ+bcwb7O5+X2D4ofnmCSEuLfQhWohEULALkQgKdiESQcEuRCIo2IVIhA4XnGy1gAqRiRSBrBHtrZbl7k8U+6lt5xzPAJvZ9Tq19SxfHhwfXMGz3iZneObSm6PHqM0jz0xp4jS1zUzMBMe/8CfhNkgA8B/uCwkuLao1vlZOpEgAmJ0OS0CVSoXOyUVStnKRLManfvg4tf3iO98Pjvec4Okec9N88UfW8My8kXW3UNt73vdBalu9eiQ4Xujj2YjFZauC4zbFrzfd2YVIBAW7EImgYBciERTsQiSCgl2IRFCwC5EInZXeHEAjrK9EWr2hRmSX5mBYCgOAkXffQW07x05S29QxnsFWPUMyigq80OD+13n/r+pUmdqc9P8CgBXLIj3WhnqD48uWraRzRo/xbLNTU9w2N8f9Z0rZ0DIuJ/VHiltGUh+xdu06arvx+ncFx2cnJuic1ZuuoraVV19DbYOreFHJbOS2OjUdvuaGevl6NIfINXDsKJ2jO7sQiaBgFyIRFOxCJIKCXYhEULALkQgd3o13oEH6PNUbdNrsitXB8ffc+x/pnNJt76G2n32f1x+b3n+C2pr1sO/5Ht5+aPoMT1qpTU9SW7F3gNp6S7x10Yo14Z3pbJHPGTvJfZyeCyfWAEAjoqAMDS4LjlfIGgLA5BhPDOrvC6sMAHDLnTzJpED8ODLKd63zy8NzAKDCaigCyESShpplnqDSJC27Dh87QueMzYV38GtNHke6swuRCAp2IRJBwS5EIijYhUgEBbsQiaBgFyIRFtL+6TIAfwlgDVqpLNvc/etmNgzgewA2otUC6l5359kFbRokoaFS45LB+g98ODj+7v/0n+mcFw5x2WJwVbjmFwDk+/ZRm3tYIqlVeV212SmeWANyPACoVXhyzesH3qC2y664NjieKXJ5sFznLYNiNeh6IhLgzFTY/5889SSds2PnS9S2ak245hoA/NuP/AG1XfHOcNul3Jp30DlTp/llPFvhElolIq9V+RJjdjK8Vj9/5h/pnCOj4eu7WuMnWsidvQ7gC+5+HYA7AHzWzK4D8ACAp939KgBPt38XQlyizBvs7j7q7i+1f54CsAfAOgD3AHik/WePAPj4UjkphFg85/WZ3cw2ArgFwHMA1rj7aNt0DK23+UKIS5QFB7uZ9QP4IYDPu/tbvufp7o7W5/nQvK1mtt3Mts9EChAIIZaWBQW7meXRCvRvu/vZL5aPmdlI2z4CYDw01923ufsWd9/SZ/x7xUKIpWXeYDczQ6sf+x53/+o5picB3N/++X4AT1x894QQF4uFZL39LoBPAdhpZi+3x74I4MsAHjOzTwN4E8C98x2o6cBsPXx3b/byumo9G64Ojv/4OS7VHDvD5ZPlQ7xWWLFUpDYj9fOOHT1E55QrPGusUOTnKpR4+6reSO29fCF8zEw2S+dUI7pQPZKllueHxN888X+D43/98J/TOW78XJbj96XdO3ZS22c++9+C41cTSQ4ADPyBnToZaRs1w7MYazO8lt8//8OPg+M7nvsXOmc41iuLMG+wu/uzAGnQBtx13mcUQnQFfYNOiERQsAuRCAp2IRJBwS5EIijYhUiEjhacdDiqRMopreJF/p795cvB8b956Dt0zk23htv+AMCV7+K2YkQOq8+Fs9tmI5JLLsdlnEyBF1G84dbbqW3DlbwFUU9P+JjZiPQWldfyvA3V8fFfU9uP/zYsvZXy/P4yvIJ/43quOkdt+/e9Rm1P/ODR4Pg9f3QfnTM1xc918jQvSIoGb4f1rz/7KbXteD4ssRWdS6I9fWFpNmPcd93ZhUgEBbsQiaBgFyIRFOxCJIKCXYhEULALkQgdlt6ABsIyT7nJCxseOnIwOJ7L8MyfqUihx0KBF19cvpxnlL3+6zeD47VIwcZibyR7bYgXURxYvoLaZmZ4YcPh4fC81avD/fLmIxeR7Pbu+iW1nTkTzg5bPsB72E1M8IyyhvPGcoP9vPDlrpfDmZFXXx0uzAkAa9dvprbYtbP/NS4B7t2zi9qKmfBjWzUwSOf0lUrB8UyGy8C6swuRCAp2IRJBwS5EIijYhUgEBbsQidDR3fgmgGny+lKZ5rXamqvCu+6bLr+MzmlEKtl6uOo1AKCnp4cfsxFuUZUldd8AYNkw33EfWruB2ty5/3MzfK3Wr18fHM9k+Ov67Czf3bfIOo6NjVFbjiTQ9EV243v7uXIxHXnMk5F2TVNT4R3+fa++QueMXL6R2sz4tXP44EFqq8/xNV5eCu/wl7KRe3GTqRPcP93ZhUgEBbsQiaBgFyIRFOxCJIKCXYhEULALkQjzSm9mdhmAv0SrJbMD2ObuXzezBwF8BsDx9p9+0d2fih2r5sB4I/z6Uq3wRIfZSljy8hKXGZpUmgDKZV4rrBnpqlOphZN1cj08EWPZqrXUtn4DT7hYOcQTYSwmHZIEidFRXi/OIw861g6rEVljy4Wlt2yOJ5IMLuNJSPXmcW6b44lIs1PhxJA3D+yjc64cDSc8AcD0DL92jh4+TG3VCp9XI92NZ+vhmocAgEJYIo49lwvR2esAvuDuL5nZAIAXzexs9byvufv/WcAxhBBdZiG93kYBjLZ/njKzPQDWLbVjQoiLy3l9ZjezjQBuAfBce+hzZrbDzB42M96GVQjRdRYc7GbWD+CHAD7v7pMAvgHgCgA3o3Xn/wqZt9XMtpvZ9sr5d5kVQlwkFhTsZpZHK9C/7e4/AgB3H3P3hrs3AXwTQLCrgbtvc/ct7r6lyL9mLYRYYuYNdmtlQjwEYI+7f/Wc8ZFz/uwTAHhmgRCi6yxkN/53AXwKwE4zO9uH6YsA7jOzm9GS4w4C+OP5DtQww2SOvL5EMnyy5bC0Uu8PS3IA4MbbFs1G5JN+UsMNAN6x6erg+ODKYTrnqmt4rbN3Xn09ta1fy1shsSUEgGJvWCorFvh6eDPyliuSfdfXwzPYMmT9G5H7y8g6vu+7ag2XMPfs2EFts5Xp4PixMS5F7t3Fjzczy9srHR8/Sm2s7RkAzLA1yfP6fyiE53AxdGG78c8CCD3jUU1dCHFpoW/QCZEICnYhEkHBLkQiKNiFSAQFuxCJ0NGCkzADSuSUkUJ++dmwfDJY4nLSVES1qE7yAoWnTp3kEz0s9c1FimXu3bOH2o4d4llS/ZHCl3mSUQYA+Z5wVlkmKKi0aNa5hBmbd+bEOD8myRAs5Pkl9/revdSWzfAndPw4L3xZqYUzx6amztA5L/z8n/nxqly2rUSKSuYi0nKZyJvufE6OrEcz8nzpzi5EIijYhUgEBbsQiaBgFyIRFOxCJIKCXYhE6Kj0ZmbIkIKDpTyXmmZILs+xQ2/QOXNFXijx14dfo7Zj41zGmTkzFRz3iKwSq9cRk5Oir8LG51k2/JRmjB/RSMFDAEDElgHP5KpVw5LX5svfwf0wfjmeOMEl0XUjkYy4V8PPZ7POi1SemeDnivUJzETkY4/YkA3LZc0sz2Fz1oMvksCoO7sQiaBgFyIRFOxCJIKCXYhEULALkQgKdiESobPSWyaDfG9/0FbIcamsmQm7WanwXljHJsMyGQDMkEwoAChEJLtVIyPB8Zk5XoSw3uQZZSxzaX4iMg47X8SPZqQYYsxWdy5fNcn5dkWKOcYKcI5ECk4eOsT7tpXL4Uy0WL+8iEoJi2lbMROR1wDA8uETFnrDffsAwGJVRwm6swuRCAp2IRJBwS5EIijYhUgEBbsQiTDvbryZlQA8A6DY/vsfuPuXzGwTgEcBrADwIoBPuUe2ZwE0zVAhO+se2cqskjml4WV0zkjvILVZMZyMAwD9g7ylkZNabQcPHKBz5sp8p74UqTOXzfKd+qzxBAmrhc/XIDXhAP64AKBe5fMaTV6PrVYNXwozZa6E7H6N16DLkGsAACbPHKc21r0qH7kGYu2wjCWgANHd+NjzmSOtuQpFvhvfZAlKi0yEqQD4kLu/C632zHeb2R0A/hTA19z9SgATAD69gGMJIbrEvMHuLc6Wd823/zmADwH4QXv8EQAfXxIPhRAXhYX2Z8+2O7iOA/gpgDcAnHb3s9+4OAKAt+AUQnSdBQW7uzfc/WYA6wHcDuCahZ7AzLaa2XYz215t8M+GQoil5bx24939NICfAfgdAMvt/5cWWQ8g2Jza3be5+xZ331KIbFIIIZaWeYPdzFaZ2fL2zz0APgxgD1pB/+/bf3Y/gCeWykkhxOJZSCLMCIBHzCyL1ovDY+7+t2a2G8CjZva/APwSwEPzHcjNUCeJJg7e0ig3tCo4vmb9BjqndzXfQqhFXuJmIi18TpM6aIU+LgH2D6+mtqj8k+EaSj5S8y7XDCeueDNSz6zBbbUyl9eqZd72qkxsETdQKHApEhEfG87lwUo1nBCViVwDmQy/FmPl+ljyDwDkSW1AACgVwtdBNlJrsElU7ljNw3mD3d13ALglML4frc/vQojfAPQNOiESQcEuRCIo2IVIBAW7EImgYBciEcxjWsLFPpnZcQBvtn9dCeBEx07OkR9vRX68ld80Pza4e1Cr7miwv+XEZtvdfUtXTi4/5EeCfuhtvBCJoGAXIhG6Gezbunjuc5Efb0V+vJXfGj+69pldCNFZ9DZeiEToSrCb2d1m9pqZ7TOzB7rhQ9uPg2a208xeNrPtHTzvw2Y2bmavnDM2bGY/NbPX2/8PdcmPB83saHtNXjazj3bAj8vM7GdmttvMdpnZf22Pd3RNIn50dE3MrGRmz5vZr9p+/M/2+CYze64dN98zM542GcLdO/oPQBatslabARQA/ArAdZ32o+3LQQAru3De9wO4FcAr54z9bwAPtH9+AMCfdsmPBwH8SYfXYwTAre2fBwDsBXBdp9ck4kdH1wStGrH97Z/zAJ4DcAeAxwB8sj3+ZwD+y/kctxt39tsB7HP3/d4qPf0ogHu64EfXcPdnAJx62/A9aBXuBDpUwJP40XHcfdTdX2r/PIVWcZR16PCaRPzoKN7iohd57UawrwNw+Jzfu1ms0gH8xMxeNLOtXfLhLGvcfbT98zEAa7roy+fMbEf7bf6Sf5w4FzPbiFb9hOfQxTV5mx9Ah9dkKYq8pr5B9153vxXA7wP4rJm9v9sOAa1XdsSLjiwl3wBwBVo9AkYBfKVTJzazfgA/BPB5d58819bJNQn40fE18UUUeWV0I9iPArjsnN9pscqlxt2Ptv8fB/A4ult5Z8zMRgCg/f94N5xw97H2hdYE8E10aE3MLI9WgH3b3X/UHu74moT86NaatM993kVeGd0I9hcAXNXeWSwA+CSAJzvthJn1mdnA2Z8BfATAK/FZS8qTaBXuBLpYwPNscLX5BDqwJtbqqfQQgD3u/tVzTB1dE+ZHp9dkyYq8dmqH8W27jR9Fa6fzDQD/vUs+bEZLCfgVgF2d9APAd9F6O1hD67PXp9Hqmfc0gNcB/AOA4S758VcAdgLYgVawjXTAj/ei9RZ9B4CX2/8+2uk1ifjR0TUBcBNaRVx3oPXC8j/OuWafB7APwPcBFM/nuPoGnRCJkPoGnRDJoGAXIhEU7EIkgoJdiERQsAuRCAp2IRJBwS5EIijYhUiE/wexH0EWyIea+QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "dV3OVgM3qJw5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nuilding the CNN model\n",
        "\n",
        "model = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "OFrThIR1S9QP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the first cnn layer\n",
        "model.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same', \n",
        "                                 activation='relu', input_shape=[32,32,3]))"
      ],
      "metadata": {
        "id": "GXKdL1-hTo5e"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the second cnn layer and max pooling layer\n",
        "model.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2,padding='valid'))"
      ],
      "metadata": {
        "id": "hmQbz01nVrz7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add third cnn layer\n",
        "model.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))"
      ],
      "metadata": {
        "id": "laKImDdVWUqk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add fourth cnn layer\n",
        "model.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))"
      ],
      "metadata": {
        "id": "WCF5Oo5GXRn0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the max pool layer\n",
        "\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2,padding='valid'))"
      ],
      "metadata": {
        "id": "aUoN-OKdXmJB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the flatenning layer -> 1D layer\n",
        "model.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "OrY8m8IJX1bv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the first fully connected layer\n",
        "model.add(tf.keras.layers.Dense(units=128,activation='relu'))\n"
      ],
      "metadata": {
        "id": "p4URfXF7YDvp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the output layer\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
      ],
      "metadata": {
        "id": "2cfo1smLYZ8p"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv50r20cY47s",
        "outputId": "bbbe0a19-d606-49bb-d6d9-225db8e447b5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               524416    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 591,274\n",
            "Trainable params: 591,274\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam', metrics=['sparse_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "vKd5pYBjY-lr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "model.fit(X_train,y_train,epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84HpYn90Z9YU",
        "outputId": "91b6cf77-789b-4fe5-e6b9-867d7cfc94f3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 234s 149ms/step - loss: 1.3190 - sparse_categorical_accuracy: 0.5209\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 232s 149ms/step - loss: 0.8653 - sparse_categorical_accuracy: 0.6944\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 232s 149ms/step - loss: 0.7105 - sparse_categorical_accuracy: 0.7516\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 232s 148ms/step - loss: 0.5929 - sparse_categorical_accuracy: 0.7919\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 232s 148ms/step - loss: 0.4989 - sparse_categorical_accuracy: 0.8240\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f61fd1e1290>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f89LriNgaPDe",
        "outputId": "a338ba25-ca44-4717-b7c7-e1a903112e66"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 12s 37ms/step - loss: 0.7725 - sparse_categorical_accuracy: 0.7400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZDONm5uiJmS",
        "outputId": "6976d095-827e-4343-ba4e-f99f7565d244"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7400000095367432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "36RjrHBdiQbI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}